# GPR Competition datasets

Dataset for the General Place Recognition Competition. You can find more details in the competition website: [http://gprcompetition.com/](http://gprcompetition.com/)

## Datasets

We provide two datasets for evaluating place recognition or global localization methods. They are

- **CMU Cross-Domain Dataset**: This dataset aims for the Large-scale 3D Localization (LiDARâ†’LiDAR) competition track. It has LiDAR point clouds and ground truth poses for 55 trajectories, collected in Pittsburgh. Each trajectory is divided into several submaps, and a submap has size 50m*50m with the distance between every two submaps being 2m. [Download](https://xxxx).  
    ![CMU_Lifelong](docs/data_pics/cmu_lifelong.png)

This dataset focuses on visual localization for UGVs using omnidirectional cameras within outdoor campus-type environments. We collected 80 real-world UAV sequences using a rover robot equipped with a 360 camera, a Velodyne VLP-16 LiDAR, a RealSense VIO and an Xsens MTI IMU. These consisted of 10 different trajectories. For each trajectory, we traversed 8 times, including forward(start point to endpoint)/backward(endpoint to start point) directions and day-light (2pm to 4:30pm)/dawn-light (6am to 7am or 5pm to 6pm). 8-times includes two forward sequences and two backward sequences during day-light and two forward and two backward sequences during dawn-light.Each trajectory is at least overlapped at one junction with the others,and some trajectories even have multiple junctions. This feature enables the dataset to be used in tasks such as LiDAR place recognition and multi-map fusion.

The original dataset contains point clouds and IMU data. For each trajectory, one sequence is being selected as the reference sequence.Its poses are generated by SLAM and later optimized by Interactive SLAM.We then used Interactive SLAM to generate the relative positions of the other sequences compared to the reference sequence.These data can be used as relative ground truth data.

In this dataset, we include:

* High resolution (1024x512) omnidirectional imagery, captured at 15fps. Timestamps are synchronized with the rest of the system.
* Timestamped IMU (linear accelerations and angular velocities)
* Timestamped VLP-16 LiDAR generated point cloud data
* Timestamped RealSense generated odometry data

Relative ground truth for each sequence compared with the corresponding selected reference sequence.

Datasets are pre-processed and you can easily manage the data with our tools. For more information about dataset, please refer to [dataset description](./docs/dataset_description.md).

## Software

Tools, such as data loader and evaluation metrics, are also provided in Python. The minimum Python version is 3.6. For package dependencies, see [requirements.txt](./requirements.txt).

## Install

The easiest way to install our tools is by using pip. We recommend the use of virtual environment such as `conda` to keep a clean software environment.

First, clone this repository:

```bash
~$ git clone https://github.com/MetaSLAM/GPR_Competition.git
```

Then, set up the enviroment. Here we create a new virtual environment via conda. You can skip the first two steps if you already have one (but still need to install requirements):

```bash
~$ conda create --name MetaSLAM python=3.6
~$ source activate MetaSLAM
(MetaSLAM) ~$ cd GPR_Competition
(MetaSLAM) ~/GPR_Competition$ pip install -r requirements.txt
```

To make this tool available for Python to import, usually we have *two* ways. You need to choose **one**:

- Add this repo to the variable $PYTHONPATH in the file .bashrc (recommended):

    ```bash
    ~$ cd GPR_Competition

    pip install .

    # Add the following lines to the end of file, then save and quit.
    #export PYTHONPATH=$PWD/GPR_Competition:$PYTHONPATH
    ```

- Install Evaluation:

    ```python
    import gpr
    #sys.path.insert(0, '~/GPR_Competition')
    print(gpr.__path__)
    ```

Finally, you have successfully installed our tools. You can have a test with `import gpr` in the python interpreter.

## Tutorial

We provide detailed documents about the usage of this package, which can be found in the `docs` folder.

## Modules

Our package organizes different functions in sub-modules. You may have a better understanding of the `gpr` package with this table:

module | description
:--:   |--
`gpr`|some common operations
`gpr.dataloader`|load dataset from disk, get images, point clouds, poses, etc.
`gpr.evaluation`|evaluate your method, such as recall@N, accuracy, PR curve
`gpr.utils`|utility, such as rotation, translation, transformation

## Quick Start

### Load data

Assume you have download the `Pittsburgh Large Scale dataset`, then you can load it and get the point cloud data:

```python
import gpr

dataset_path = 'PATH_TO_THE_DATASET'
dataset = gpr.load_dataset(dataset_path) # List[traj1, traj2, ...]

traj0 = dataset[0] # select the first trajectory
frame_id = 88      # get the data of 88th frame
pcd = traj0.get_point_cloud(frame_id) # open3d.geometry.PointCloud
```

For more about the data loader, please refer to [loading_data.md](./docs/loading_data.md).
